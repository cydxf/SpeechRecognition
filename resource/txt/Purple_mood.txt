第一次接触神经网络时候一定会觉得非常奇怪这些线这些方框是什么东西还有什么是输入输出隐藏层编制权重还有激活函数损失函数然后更不巧的是如果你在看不懂这些情况下又去看了代码你会发现更加的离谱更加的抽象完全不知道这个代码在干些什么那么我当初也是和你完全一样跟我学习和理解之后呢我发现其实原理是非常简单的这里举一个简单的例子让你也能快速理解不妨先给视频点个免费的赞吧 至少生物的神经网络和我们这种机器学习用的神经网络在底层原理上是完全不同的所以作为初学者一定要知道这个神经网络呢只是示意图长得像一个神经网络我们看着像不像一个一个神经元然后如果有很多输入法是连起来就会形成交叉看起来就像一张网络一样所以他就神经网络那我们看看再不谈神经网络前提下右边这个图正常人是如果你和的我们很容易发现上面这幅图呢是不是就等于下面这三条折线进行相加呀你们看到 我们做过一个线性操作那我们这里是对这个人六函数则函数本身进行一次限行操作然后再看看前面这些比如我们这个三里面是不是它等于R二括号x减二也就是R括号二x减四没有发现这个里面是对x先进行一次限行操作也就说对x进行一次限行操作然后再进行一次2.4限行操作那就可以得到我们要的这个任意的这种形状形状的函数那么一个流程图的形式来 没有什么函数可以方便的去表示这样的折线呢那这时我们就不得不提到一个函数叫做RE函数我们把它记作r x那这个value那知道这个函数之后是不是这三个函数就非常好表示了首先呢我们需要知道这个函数想要平移或者缩放应该怎么办呢比如我们想要x往右移一格让他从一这边开始往上走那是不是只要按括号x减一就行了然后如果往左移就是 左侧是一个输入x右侧是输出y中间是一层隐藏层然后右侧呢是这个神经网络要干的事情也是说我们需要你和这个预估值y使它与这个真实值y重合首先需要解释一点是这个神经网络虽然名字叫神经网络可他和我们生物上的神经网络除了名字和这个图画出来形式比较像以外并没有其他什么共同点了至少生物的神经网 加一个东西其实就可以从这个到这个那像这个呢其实也非常简单那就在前面加一个负号呗对不对那我们把这样的这种形式ax加B的这种操作呢叫做一个线性操作 你们看到y等于一加二加三也就是说在这一点斜率进行了一个改变然后在这一点吗这两个相加之后斜率是它然后在这一点嘛这三者相加的斜率呢是它也就是说只要把这三条折线加起来就得到为那么现在假设这上面这条歪的斜率分别是零一负一和一然后在2012突变形成了一条折线那么下面这三个函数斜率分别应该就是1负二和三那么有没有什么函数可以方便 又是另外一个任意位置这种东西他分别就对应的123也就是说我们给你三个自由度给你三三个任意位置的这种东西要求你呢去把它加起来可以得到它那么这神经网络就是在城市这三个任意位置这种东西看看怎么读怎么上下楼左右挪然后调整斜率可以让他等于它下面就来介绍一些小白可能不太懂的名词首先什么是权重和偏置呢我们刚才是不是提到一次线性操作呀就是对输入进行一个ax加B操作那这个B呢就是 你一个流程图的形式来说明对于一个数级x我们先进行一个限行操作l与我们这里面这个里面这个东西二括号x减一然后再进行一个非线性操作2也就是它然后再进行一次限行操作l比如说我们这里取个符号或者我们如果要把它往上下移的话还需要加一个B然后就得到一个任意位置的这种东西那再看刚才这个一二三是不是都是属于任意位置这种东西那把他们加起来是不是就得到了它呀那我们现在再来看这个神经网络示意图 大括号x加一对不对那么如何进行缩放呢比如我们要把它变成这样协定能变成原来两倍也就是说把它往S往外走这边挤那是不是就变成二二x那这个缩放呢是允许你任意的往里面挤往里面挤的话比如说rrs这样呢它整个就会被拉过来斜率变为原来两杯也允许你往外拉比如说啊二分之X那是协议就会变缓而且还允许你拿一个复制比如说阿富二x那就是它的反方向也就是 再来看这个神经网络示意图是不是就恍然大悟了只不过他这个写法和我们流程图写法有所区别他这样写的是为了美观所以可能会导致有些小白看不懂我们对输入的人呢进行一次l操作也就是一次线性操作呀然后呢在经过一个隐藏层神经元二实际上就是一个非线性操作案然后再经过一次线性操作就可以输出了那他这条输出呢是不是就一个任意味着这种东西然后这条输出呢是另外一个任意位置这种东西然后这条输出呢又是另外一个任意位置这种 就是他的反方向也就是到这边来了那有了平移和缩放那是不是就意味着我们可以把这个转折点挪到任意一个位置去了并且这条线斜率也是可以随意变化的但是你没有发现有两个缺点那就是这个点呢它只能在x轴上动它并不能往上走也就是他只具有一个一个维度他不能跑到其他地方比如我们想要一个这样的函数那就不行还有个问题呢是这条线它始终是在上方的因为你看这个原函数无论你怎么样的放松这 日本人工智能聊天机器人欢迎大家体验那本期视频就到此为止了如果你看懂的话就先给个三年吧如果没有看懂欢迎在评论区进行补充和提问谢谢大家 为什么叫隐藏层呢因为他他不体现在输出上也就是说你的输入并不是直接通过一个什么函数直接接到输出上面那么中间就需要经过这个隐藏层实际经过我们刚才推到其实可以发现这个输出是可以直接写成输入的一种函数的只不过这样的非常的麻烦而且实际过程中我们很难直接找到这样一个函数比如说把一和一加二加三直接写出来其实就按x加这个加这个对不对但是我们实际中不可能人去写出这样一种特殊函数形式所以我们就需要隐藏层的帮忙 拿这个B呢就是拔牙齿编制a呢就是权重位置那这里呢我们把鼠标放到任一条线上都可以看到他说wait是什么然后再放了这个点上呢可以看到偏置是什么那这两个加起来呢其实就是对x的一个线性操作也就是w x加B你跟我们刚才写的ax加B是一样的只不过神经网络里面肯定不能把它叫做什么斜率和结局对吧造成全中和编制更有意义然后什么是隐藏层的隐藏层就是中间这一层为什么叫隐藏层呢 所以我们就需要隐藏层的帮忙如果你刚开始就直接写成这种形式实际上就没有一条线拉过去没有什么隐藏层了对不对然后呢就是激活函数是什么你看到我们这个方框里面写了个二这个R呢就表呢就是一种激活函数激活函数的必须是非线性的我们可以看到这边有很多种计划函数它这边也给出一种线性的机构函数使用线性激活函数其实相当于没有什么激活作用激活函数位置在这边他为什么叫激活呢你就说史前面就输入变得有 如果是三条线是怎么加他最终都是一条线实际上也就是我这边说这个然后最后什么是损失函数呢就看这个图就可以了你看最后你和的y是不是离这个真实之外有一定的差距那么我们就需要创造一个损失函数来描述这个差距通常可以用一个最简单的军方误差来表示也就是说这个值你真是值得差距的平方然后这样加起来当然也可以是绝对值然后我们通过调整这个线性和非线性操作这些参数实际上只有四个 老实际上只有四个也就这边这个线性操作有两个参数对吧这边有两个参数这个东西这个非建议操作是固定的没有参数那总共这里面这边两个参数这边两个参数总共有12个参数我们调整这12个参数呢最终使得这个损失函数最小也是说y和y的差距越小你至于怎么调整那就是等你先把这个看懂之后才能再说内容了那么这就是人工智能神经网络和机器学习的基本原理在我的粉丝群中就有一个人工智能聊天机器人 重点呢在于非线性因为如果是一种线性理科的话那一眼就看出来根本用不着用神经网络这种工具那既然是非线性的如果你这个位置上仍然用一个线性函数好用最终结果一定是这样的就是你前面进行的线性操作然后如果这边不是20的话你又进行现行操作然后最后再进行现行操作实际上呢就相当于一次线性合作你看这个函数我们永远可以直接把它画成一个n x加B的 1 4加B的这种格式对不对你这么多参数实际上就相当于一次线性操作一条线直接拉过去所以说我们几乎还是一定不能选取一个线性函数也就是说他这个计划函数自己要有一定的特征比如像我们这边这个RS他就是说长得像这样那么我们靠长得像这样的东西就能你和他对不对如果只长得像一条线的你无论怎么加怎么剪他最终都是一条线对不对但是如果长得像这样的那你通过多个长得像这样的东西你看就可以弄出他了如果是三条线是 